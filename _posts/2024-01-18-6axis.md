---
layout: dongjun
title: "6-Axis Manipulator"
date:   2024-01-18 21:03:36 +0800
description: "Within RH+"
categories: ROS2 RH+
---

Yonsei University's Roboin club is undertaking the RH+ project to design, build, and control a ~40 cm humanoid robot with environment perception. Following our initial 2-axis manipulator, we are now developing a **6-axis manipulator**, which is currently **in progress**. This advanced arm aims to tackle more complex tasks such as object pick-and-place, stacking, and obstacle avoidance planning.

<div class="btn-row">
  <a href="https://chanhui-robot.notion.site/7-Axis-Robot-Arm-627533d1fb984b588b3fc5142f86f195?pvs=4" target="_blank" class="btn">
    <img src="https://upload.wikimedia.org/wikipedia/commons/e/e9/Notion-logo.svg" alt="Notion" class="btn-icon"> Notion
  </a>
  <a href="https://github.com/RHplusLab/RHp_apriltag_ros2" target="_blank" class="btn">
    <img src="https://github.githubassets.com/images/modules/logos_page/GitHub-Mark.png" alt="GitHub" class="btn-icon"> GitHub
  </a>
</div>

## Abstract
This project focuses on a 6-axis robotic arm designed for **pick-and-place**, **object stacking**, and **real-time obstacle avoidance planning**. The hardware has already been assembled, and current efforts are directed toward **motion control and task execution** using **MoveIt2 Task Constructor and Hybrid Planning**. Additionally, we are studying **FoundationPose** to enhance 6D object pose estimation for more precise manipulation.

## Features

### 1. MoveIt2 Integration
Before implementing advanced planning, we first integrated **MoveIt2** with our robotic arm to establish a reliable connection between hardware and software. MoveIt2 facilitates **real-time path planning** and **collision detection** in a 3D environment, ensuring that the robotic arm can move safely and accurately toward target positions while avoiding obstacles.

The following video demonstrates our MoveIt2 integration in action:

<div class="video-container">
  <iframe width="420" height="315"
          src="https://youtube.com/embed/T8C6xuPLzNw"
          frameborder="0"
          allowfullscreen>
  </iframe>
</div>


### 2-1. 6D Pose Estimation with AprilTag

AprilTag is a visual fiducial system widely used for pose estimation and camera calibration. It consists of square black-and-white patterns (similar to 2D barcodes) that can be detected and identified in images. The system provides robust detection and computes the precise 3D position and orientation (pose) of each tag relative to the camera.
>>> [AprilTag official page](https://april.eecs.umich.edu/software/apriltag.html)


#### AprilTagVideo

<div class="video-container">
  <iframe width="420" height="315"
          src="https://www.youtube.com/embed/BMONxk_isWE"
          frameborder="0"
          allowfullscreen>
  </iframe>
</div>


### 2-2. 6D Pose Estimation with FoundationPose

To accurately determine the **6D pose of objects**, we utilized the **FoundationPose** model, which was selected as a **CVPR 2024 Highlight** ([Paper Link](https://arxiv.org/abs/2312.08344)). We leveraged the **existing open-source implementation** to test its performance in real-world robotic applications.

#### Initial Testing: Banana Object
In the first experiment, we used a **banana** as the test object to verify the model’s ability to correctly estimate the 6D pose under normal conditions.

<div class="video-container">
  <iframe width="420" height="315"
          src="https://youtube.com/embed/C_fPBnyGWO0"
          frameborder="0"
          allowfullscreen>
  </iframe>
</div>

#### Occlusion Experiment: Handling Blocked Objects  
In real-world robotic applications, parts of an object may become **occluded** by the robot's own body or hand during manipulation. To simulate this scenario, we conducted an experiment where the object was intermittently blocked.  

As observed in the **latter part of the video**, the model sometimes successfully recovered from occlusions, but in other cases, it **failed to re-estimate the pose** entirely.

<div class="video-container">
  <iframe width="420" height="315"
          src="https://youtube.com/embed/hhQurO7WNxg"
          frameborder="0"
          allowfullscreen>
  </iframe>
</div>

### Further Study and Improvements

To gain a **deeper understanding of the deep learning models** used in FoundationPose, we participated in **Naver Boostcamp**, a **7-month intensive deep learning program**. Additionally, we organized a **6D Pose Estimation study group** ([Notion Link](https://principled-nation-e2a.notion.site/NOVA-Navigators-Of-Vision-and-AI-Robotics-101921078eca80d29313d4bb780ed7ad?pvs=4)) to further explore this topic.  

Currently, our understanding of **FoundationPose** remains closer to **memorization rather than true comprehension**. Moving forward, we aim to **analyze the model more deeply** and, if necessary, **fine-tune it using additional training data**. If additional training is required, we plan to **rent servers** to conduct large-scale training sessions.

---

## System Overview

### Hardware Components

Our robotic system consists of the following hardware components:

#### **Perception & Computing**
- **Intel RealSense D455** - Depth camera for advanced environment perception  
- **NVIDIA Jetson Orin Nano Super** - Main onboard computing unit  

#### **Actuation & Structural Components**
- **Servo Motors (HTD-45H) + Metal Horn (7 sets)**
  - [Servo Motor (HTD-45H)](https://www.aliexpress.com/item/1005004845976999.html)  
  - [Metal Horn](https://www.aliexpress.com/item/1005004846129434.html)  

- **Aluminum Plates** (Various sizes, [Reference for plate count](https://www.notion.so/0194e99253fd41d8a5211275507b708c?pvs=21))  
  - 200×300×1.5 (3 pieces)  
  - 100×100×4 (2 pieces)  
  - 100×100×5 (2 pieces)  
  - 100×100×6 (4 pieces)  
  - 120×100×6 (3 pieces)  
  - 100×100×8 (2 pieces)  
  - 100×100×12 (3 pieces)  

- **Aluminum Profiles**  
  - [4040 Profiles](https://smartstore.naver.com/bandotec/products/373076928)  
  - [2020 Profiles](https://smartstore.naver.com/bandotec/products/7230610259)  
  - Various lengths: 100mm, 40mm, 150mm, 400mm  
  - Accessories: Spring nuts, joint clips, etc.  

- **Wooden Plates**  
  - [Store Link](https://smartstore.naver.com/goodtree/products/4686984331)  
  - 150×150×12 (2 pieces), 415×300×12 (2 pieces)  

#### **Fasteners & Mechanical Components**
- **M3 Nylon Nuts (100 units)** ([Store Link](https://smartstore.naver.com/boltoutlet/products/4223627261))  
- **Round-Head Bolts** ([Store Link](https://smartstore.naver.com/hanarobolt/products/6479781399))  
  - Sizes: M2×4, M2×6, M2×35, M3×15, M5×14, etc.  
  - Some purchased from AliExpress or RoboBuilder due to availability  
- **Standard Hex Bolts** ([Link](https://naver.me/5LuXA8Hz))  
  - Sizes: M3×8, M3×10, etc.  
- **Countersunk Bolts (for profile mounting)** ([Link](https://naver.me/FQR2Ip0A))  
  - Sizes: M5×22, M5×30, etc.  
- **LM Guide** ([Store Link](https://smartstore.naver.com/nasspop/products/7073064025))  
  - Short-type block ×2, rail 200mm  
- **Bearings** (Pending purchase)  
  - [AXK5070](https://smartstore.naver.com/allbearing/products/4209406705)  

#### **Tools & Other Materials**
- **Hex Driver** ([Link](https://smartstore.naver.com/micromro/products/6274211943))  
  - Precision hex wrench driver (1.27mm)  
- **Teflon Sheet** ([Link](https://smartstore.naver.com/engp1080/products/236238941))  

---

### Software Stack

The system runs on the following software stack:

- **Ubuntu 22.04**   
- **ROS2 (Humble)**  
- **MoveIt2**   
- **C++** 
- **Python3.10**

---
## Making Video
A brief look at how we assembled the mechanical parts and tested the motion:

<div class="video-container">
  <iframe width="420" height="315"
          src="https://www.youtube.com/embed/zW7u8YMU71c"
          frameborder="0"
          allowfullscreen>
  </iframe>
</div>


## Additional Commentary
Developing a 6-axis arm involves a significantly more complex mechanical design and advanced kinematic configurations. By integrating ROS2 and MoveIt2, we aim to achieve **precise, real-time control**. Our future work will include improved object recognition, **6D pose estimation**, and refined grasping algorithms for diverse tasks. This project is evolving rapidly, and we will continue to share progress as new features are implemented.
